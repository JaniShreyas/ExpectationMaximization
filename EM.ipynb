{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First need to create k Gaussians for a mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4), (112, 1))"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The book suggested first running k means a few times and then using that as those as the Gaussians\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "XFull = data\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(XFull, target)\n",
    "\n",
    "yTrain = yTrain.reshape(-1,1)\n",
    "yTest = yTest.reshape(-1,1)\n",
    "XTrain.shape, yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "39\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\unova\\anaconda3\\envs\\nb\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters = k, max_iter= 1)\n",
    "kmeans.fit(XTrain, yTrain)\n",
    "\n",
    "pointsInEachCluster = [XTrain[kmeans.labels_ == i] for i in range(k)]\n",
    "print(len(pointsInEachCluster[0]))\n",
    "print(len(pointsInEachCluster[1]))\n",
    "print(len(pointsInEachCluster[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.88510638, 2.72765957, 4.42765957, 1.45319149]),\n",
       " array([[0.18086031, 0.05172525, 0.12129047, 0.03015726],\n",
       "        [0.05172525, 0.09421832, 0.05443571, 0.03240981],\n",
       "        [0.12129047, 0.05443571, 0.27813136, 0.13045328],\n",
       "        [0.03015726, 0.03240981, 0.13045328, 0.0960222 ]]))"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = kmeans.cluster_centers_\n",
    "means = []\n",
    "covMats = []\n",
    "for i in range(len(pointsInEachCluster)):\n",
    "    points = pointsInEachCluster[i]\n",
    "    means.append(centers[i])\n",
    "    covMat = np.cov(points.T)\n",
    "    covMats.append(covMat)\n",
    "\n",
    "means[0], covMats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = 1 / len(means)\n",
    "priors = [prior for i in range(len(means))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal(x, mean, cov):\n",
    "    d = x.shape[0]\n",
    "    det = np.linalg.det(cov)\n",
    "    inv = np.linalg.inv(cov)\n",
    "    exponent = -0.5 * np.matmul(np.matmul((x - mean).T, inv), (x - mean))\n",
    "    coefficient = 1 / ((2 * np.pi) ** (d / 2) * np.sqrt(det))\n",
    "    return coefficient * np.exp(exponent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15915494309189535"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multivariate_normal(np.array([1, 2]), np.array([1, 2]), np.array([[1, 0], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18086031 0.05172525 0.12129047 0.03015726]\n",
      " [0.05172525 0.09421832 0.05443571 0.03240981]\n",
      " [0.12129047 0.05443571 0.27813136 0.13045328]\n",
      " [0.03015726 0.03240981 0.13045328 0.0960222 ]]\n",
      "[5.88510638 2.72765957 4.42765957 1.45319149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23677937 0.07778165 0.19107901 0.06231944]\n",
      " [0.07778165 0.10606247 0.08153701 0.04018368]\n",
      " [0.19107901 0.08153701 0.2409081  0.07378545]\n",
      " [0.06231944 0.04018368 0.07378545 0.03516221]]\n",
      "[5.94146184 2.74170488 4.25580933 1.31485304]\n"
     ]
    }
   ],
   "source": [
    "print(covMats[0])\n",
    "print(means[0])\n",
    "# I need take the current values of means, covariance and priors and calculate the h_ti\n",
    "\n",
    "# h_ti is the posterior probability of the ith data point belonging to the ith cluster for the t_th data point given the point\n",
    "# and the previous values of the means, covariance and priors\n",
    "\n",
    "# so just a normal distribution with the mean and covariance of the cluster\n",
    "\n",
    "\n",
    "def getPosteriorForAllClusters(xt, currMeans, currCov, currPriors):\n",
    "    posterior = []\n",
    "    for i in range(len(currMeans)):\n",
    "        mean = currMeans[i]\n",
    "        cov = currCov[i]\n",
    "        prior = currPriors[i]\n",
    "        probab = multivariate_normal(xt, mean, cov)\n",
    "        posterior.append(probab * prior)\n",
    "    \n",
    "    # normalize\n",
    "    posterior = np.array(posterior)\n",
    "    posterior = posterior / np.sum(posterior)\n",
    "\n",
    "    return posterior\n",
    "\n",
    "\n",
    "def getPosteriorForAllDataPoints(X, currMeans, currCov, currPriors):\n",
    "    posterior = []\n",
    "    for i in range(len(X)):\n",
    "        xt = X[i]\n",
    "        posterior.append(getPosteriorForAllClusters(xt, currMeans, currCov, currPriors))\n",
    "    return np.array(posterior)\n",
    "\n",
    "# Print which cluster each data point has most probability of belonging to\n",
    "def printPredictions(X, currMeans, currCov, currPriors):\n",
    "    posterior = getPosteriorForAllDataPoints(X, currMeans, currCov, currPriors)\n",
    "    predictions = np.argmax(posterior, axis = 1)\n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "def getNewMeans(X, currMeans, posteriors):\n",
    "    newMeans = []\n",
    "    # use the conscise numpy way of doing this\n",
    "    for i in range(len(currMeans)):\n",
    "        mean = np.sum(posteriors[:, i].reshape(-1, 1) * X, axis = 0) / np.sum(posteriors[:, i])\n",
    "        newMeans.append(mean)\n",
    "    \n",
    "    # This is just for verifying whether the conscise way copilot gave is correct and damn is it nice\n",
    "    # newMeans2 = []\n",
    "    # for i in range(len(currMeans)):\n",
    "    #     s = 0\n",
    "    #     for j in range(len(X)):\n",
    "    #         s += posterior[j, i] * X[j]\n",
    "    #     newMeans2.append(s / np.sum(posterior[:, i]))\n",
    "    \n",
    "    # print(newMeans2)\n",
    "    \n",
    "    return newMeans\n",
    "\n",
    "def getNewCovMats(X, currMeans, posteriors):\n",
    "    newCovMats = []\n",
    "    for i in range(len(currMeans)):\n",
    "        mean = currMeans[i]\n",
    "        covMat = np.zeros((len(mean), len(mean)))\n",
    "        for j in range(len(X)):\n",
    "            diff = X[j] - mean\n",
    "            diff = diff.reshape(-1, 1)\n",
    "            covMat += posteriors[j, i] * np.matmul(diff, diff.T)\n",
    "        covMat /= np.sum(posteriors[:, i])\n",
    "        newCovMats.append(covMat)\n",
    "    return newCovMats\n",
    "\n",
    "def getNewPriors(X, currMeans, posteriors):\n",
    "    newPriors = []\n",
    "    for i in range(len(currMeans)):\n",
    "        newPriors.append(np.sum(posteriors[:, i]) / len(X))\n",
    "    return newPriors\n",
    "\n",
    "def getNewParams(X, currMeans, currCov, currPriors):\n",
    "    posteriors = getPosteriorForAllDataPoints(X, currMeans, currCov, currPriors)\n",
    "    means = getNewMeans(X, currMeans, posteriors)\n",
    "    covMats = getNewCovMats(X, currMeans, posteriors)\n",
    "    priors = getNewPriors(X, currMeans, posteriors)\n",
    "    return means, covMats, priors\n",
    "\n",
    "for i in range(100):\n",
    "    means, covMats, priors = getNewParams(XTrain, means, covMats, priors)\n",
    "\n",
    "print(covMats[0])\n",
    "\n",
    "print(means[0])\n",
    "\n",
    "# The outputs are similar so why does my EM give all wrong predictions when the kmeans always gives some right predictions\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
