{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First need to create k Gaussians for a mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic dataset with 3 classes with predefined means and covariances\n",
    "def createSyntheticData(means, covMats, priors, n):\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        r = rd.random()\n",
    "        if r < priors[0]:\n",
    "            data.append(np.random.multivariate_normal(means[0], covMats[0]))\n",
    "        elif r < priors[0] + priors[1]:\n",
    "            data.append(np.random.multivariate_normal(means[1], covMats[1]))\n",
    "        else:\n",
    "            data.append(np.random.multivariate_normal(means[2], covMats[2]))\n",
    "    return np.array(data)\n",
    "\n",
    "# Create some new very distinct means and covariances\n",
    "originalMeans = [[0,0], [10,10], [20,20]]\n",
    "originalCovMats = [[[1,0],[0,1]], [[1,0],[0,1]], [[1,0],[0,1]]]\n",
    "originalPriors = [1/3, 1/3, 1/3]\n",
    "n = 1000\n",
    "data = createSyntheticData(originalMeans, originalCovMats, originalPriors, n)\n",
    "XTrain, XTest = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\unova\\anaconda3\\envs\\nb\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "261\n",
      "231\n",
      "[9.93426952 9.92103233] [[1.02265631 0.0359046 ]\n",
      " [0.0359046  1.02544892]]\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters = k, max_iter= 1)\n",
    "kmeans.fit(XTrain)\n",
    "\n",
    "pointsInEachCluster = [XTrain[kmeans.labels_ == i] for i in range(k)]\n",
    "print(len(pointsInEachCluster[0]))\n",
    "print(len(pointsInEachCluster[1]))\n",
    "print(len(pointsInEachCluster[2]))\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "means = []\n",
    "covMats = []\n",
    "for i in range(len(pointsInEachCluster)):\n",
    "    points = pointsInEachCluster[i]\n",
    "    means.append(centers[i])\n",
    "    covMat = np.cov(points.T)\n",
    "    covMats.append(covMat)\n",
    "\n",
    "print(means[0], covMats[0])\n",
    "\n",
    "prior = 1 / len(means)\n",
    "priors = [prior for i in range(len(means))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multivariate_normal(x, mean, cov):\n",
    "#     d = x.shape[0]\n",
    "#     det = np.linalg.det(cov)\n",
    "#     inv = np.linalg.inv(cov)\n",
    "#     exponent = -0.5 * np.matmul(np.matmul((x - mean).T, inv), (x - mean))\n",
    "#     coefficient = 1 / ((2 * np.pi) ** (d / 2) * np.sqrt(det))\n",
    "#     return coefficient * np.exp(exponent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_normal(np.array([1, 2]), np.array([1, 2]), np.array([[1, 0], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([9.93426952, 9.92103233]), array([20.07936625, 20.04388117]), array([0.0499462 , 0.00616266])]\n"
     ]
    }
   ],
   "source": [
    "# I need take the current values of means, covariance and priors and calculate the h_ti\n",
    "\n",
    "# h_ti is the posterior probability of the ith data point belonging to the ith cluster for the t_th data point given the point\n",
    "# and the previous values of the means, covariance and priors\n",
    "\n",
    "# so just a normal distribution with the mean and covariance of the cluster\n",
    "\n",
    "\n",
    "def getPosteriorForAllClusters(xt, currMeans, currCov, currPriors):\n",
    "    posterior = []\n",
    "    for i in range(len(currMeans)):\n",
    "        mean = currMeans[i]\n",
    "        cov = currCov[i]\n",
    "        prior = currPriors[i]\n",
    "        probab = multivariate_normal.pdf(xt, mean, cov)\n",
    "        posterior.append(probab * prior)\n",
    "    \n",
    "    # normalize\n",
    "    posterior = np.array(posterior)\n",
    "    posterior = posterior / np.sum(posterior)\n",
    "\n",
    "    return posterior\n",
    "\n",
    "\n",
    "def getPosteriorForAllDataPoints(X, currMeans, currCov, currPriors):\n",
    "    posterior = []\n",
    "    for i in range(len(X)):\n",
    "        xt = X[i]\n",
    "        posterior.append(getPosteriorForAllClusters(xt, currMeans, currCov, currPriors))\n",
    "    return np.array(posterior)\n",
    "\n",
    "def getNewMeans(X, currMeans, posteriors):\n",
    "    newMeans = []\n",
    "    # use the conscise numpy way of doing this\n",
    "    for i in range(len(currMeans)):\n",
    "        mean = np.sum(posteriors[:, i].reshape(-1, 1) * X, axis = 0) / np.sum(posteriors[:, i])\n",
    "        newMeans.append(mean)\n",
    "    \n",
    "    # This is just for verifying whether the conscise way copilot gave is correct and damn is it nice\n",
    "    # newMeans2 = []\n",
    "    # for i in range(len(currMeans)):\n",
    "    #     s = 0\n",
    "    #     for j in range(len(X)):\n",
    "    #         s += posterior[j, i] * X[j]\n",
    "    #     newMeans2.append(s / np.sum(posterior[:, i]))\n",
    "    \n",
    "    # print(newMeans2)\n",
    "    \n",
    "    return newMeans\n",
    "\n",
    "def getNewCovMats(X, currMeans, posteriors):\n",
    "    newCovMats = []\n",
    "    for i in range(len(currMeans)):\n",
    "        mean = currMeans[i]\n",
    "        covMat = np.zeros((len(mean), len(mean)))\n",
    "        for j in range(len(X)):\n",
    "            diff = X[j] - mean\n",
    "            diff = diff.reshape(-1, 1)\n",
    "            covMat += posteriors[j, i] * np.matmul(diff, diff.T)\n",
    "        covMat /= np.sum(posteriors[:, i])\n",
    "        newCovMats.append(covMat)\n",
    "    return newCovMats\n",
    "\n",
    "def getNewPriors(X, currMeans, posteriors):\n",
    "    newPriors = []\n",
    "    for i in range(len(currMeans)):\n",
    "        newPriors.append(np.sum(posteriors[:, i]) / len(X))\n",
    "    return newPriors\n",
    "\n",
    "def getNewParams(X, currMeans, currCov, currPriors):\n",
    "    posteriors = getPosteriorForAllDataPoints(X, currMeans, currCov, currPriors)\n",
    "    means = getNewMeans(X, currMeans, posteriors)\n",
    "    covMats = getNewCovMats(X, currMeans, posteriors)\n",
    "    priors = getNewPriors(X, currMeans, posteriors)\n",
    "    return means, covMats, priors\n",
    "\n",
    "for i in range(100):\n",
    "    means, covMats, priors = getNewParams(XTrain, means, covMats, priors)\n",
    "\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([9.93426952, 9.92103233]), array([20.07936625, 20.04388117]), array([0.0499462 , 0.00616266])]\n",
      "[1 1 0 2 2 0 0 2 2 1 2 2 2 2 1 2 0 2 2 2 1 1 2 1 1 2 1 1 2 1 1 2 2 1 1 1 0\n",
      " 0 0 1 2 1 1 0 0 0 1 1 2 2 0 1 1 1 2 2 2 0 0 0 1 1 1 1 2 1 1 1 1 2 1 1 1 0\n",
      " 2 0 2 0 1 0 2 0 0 1 2 0 1 2 2 1 1 0 2 1 2 1 2 0 2 0 2 1 1 2 2 1 1 1 1 0 2\n",
      " 0 2 0 2 1 2 1 1 1 0 0 0 2 0 0 2 2 1 2 2 2 2 1 1 2 1 1 0 1 1 1 1 1 2 1 0 2\n",
      " 1 1 0 2 1 2 1 1 0 2 2 1 0 2 1 1 1 2 2 0 0 1 2 1 0 0 2 1 0 1 0 1 1 0 1 2 1\n",
      " 1 0 0 1 0 1 1 2 0 2 2 0 2 0 1 2 2 1 2 1 1 0 1 1 2 2 2 2 1 0 0 1 2 0 2 0 2\n",
      " 2 1 2 2 0 1 2 2 2 2 0 0 1 1 2 1 0 0 1 0 1 2 2 2 0 2 0 0]\n",
      "[1 1 0 2 2 0 0 2 2 1 2 2 2 2 1 2 0 2 2 2 1 1 2 1 1 2 1 1 2 1 1 2 2 1 1 1 0\n",
      " 0 0 1 2 1 1 0 0 0 1 1 2 2 0 1 1 1 2 2 2 0 0 0 1 1 1 1 2 1 1 1 1 2 1 1 1 0\n",
      " 2 0 2 0 1 0 2 0 0 1 2 0 1 2 2 1 1 0 2 1 2 1 2 0 2 0 2 1 1 2 2 1 1 1 1 0 2\n",
      " 0 2 0 2 1 2 1 1 1 0 0 0 2 0 0 2 2 1 2 2 2 2 1 1 2 1 1 0 1 1 1 1 1 2 1 0 2\n",
      " 1 1 0 2 1 2 1 1 0 2 2 1 0 2 1 1 1 2 2 0 0 1 2 1 0 0 2 1 0 1 0 1 1 0 1 2 1\n",
      " 1 0 0 1 0 1 1 2 0 2 2 0 2 0 1 2 2 1 2 1 1 0 1 1 2 2 2 2 1 0 0 1 2 0 2 0 2\n",
      " 2 1 2 2 0 1 2 2 2 2 0 0 1 1 2 1 0 0 1 0 1 2 2 2 0 2 0 0] hi\n",
      "[array([9.93426952, 9.92103233]), array([20.07936625, 20.04388117]), array([0.0499462 , 0.00616266])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print which cluster each data point has most probability of belonging to\n",
    "def getPredictions(X, currMeans, currCov, currPriors)->np.ndarray:\n",
    "    print(currMeans)\n",
    "    posterior = getPosteriorForAllDataPoints(X, currMeans, currCov, currPriors)\n",
    "    predictions = (np.argmax(posterior, axis = 1))\n",
    "    return predictions\n",
    "\n",
    "print(getPredictions(XTest, means, covMats, priors))\n",
    "print(kmeans.predict(XTest), \"hi\")\n",
    "\n",
    "getPredictions(XTrain, means, covMats, priors) == kmeans.predict(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.99462016e-02 6.16266113e-03]\n",
      " [2.00793662e+01 2.00438812e+01]\n",
      " [9.93426952e+00 9.92103233e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 0, 1, 1, 1, 0, 2, 1, 1,\n",
       "       2, 0, 1, 2, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1, 2, 2, 2, 1, 2, 0, 2, 2,\n",
       "       0, 1, 1, 2, 0, 0, 0, 2, 0, 1, 0, 0, 1, 1, 1, 0, 2, 2, 1, 1, 2, 2,\n",
       "       1, 1, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 1, 2, 2, 2,\n",
       "       2, 1, 2, 1, 0, 1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 1, 1, 1, 1, 2, 0, 0,\n",
       "       2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 0, 1, 0, 2, 1, 2, 2, 0, 1, 0, 2, 2,\n",
       "       1, 2, 2, 1, 2, 2, 1, 2, 0, 1, 1, 0, 1, 2, 1, 1, 2, 1, 2, 2, 0, 2,\n",
       "       1, 1, 2, 0, 1, 0, 1, 0, 0, 2, 1, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 2,\n",
       "       1, 2, 2, 2, 1, 2, 1, 1, 1, 0, 1, 0, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1,\n",
       "       2, 1, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 2, 1, 1, 2, 1, 2, 0, 2, 0, 1, 0, 2, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 2, 0, 0, 2, 1, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 0, 2, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 1, 1, 0, 2, 1, 0, 1, 0, 1,\n",
       "       2, 2, 0, 2, 0, 2, 1, 2, 0, 1, 1, 2, 2, 0, 0, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 2, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2,\n",
       "       1, 2, 2, 0, 0, 1, 1, 2, 2, 2, 2, 0, 2, 2, 1, 0, 1, 0, 1, 2, 0, 2,\n",
       "       2, 0, 0, 1, 2, 1, 2, 1, 1, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2,\n",
       "       2, 2, 0, 2, 1, 2, 2, 0, 2, 1, 1, 2, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
       "       1, 1, 2, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 2, 0, 1, 1,\n",
       "       1, 2, 0, 1, 2, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 2, 1, 0, 0, 2,\n",
       "       1, 2, 0, 1, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0, 2, 2, 1, 0,\n",
       "       1, 1, 2, 2, 2, 0, 2, 2, 1, 1, 2, 2, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       2, 1, 0, 1, 0, 2, 1, 0, 2, 2, 1, 2, 2, 2, 1, 0, 2, 2, 1, 1, 1, 0,\n",
       "       0, 1, 0, 2, 2, 1, 1, 2, 1, 2, 1, 0, 2, 2, 0, 2, 2, 0, 2, 0, 1, 0,\n",
       "       2, 2, 2, 2, 1, 2, 1, 1, 0, 2, 0, 2, 0, 2, 0, 1, 0, 1, 2, 2, 1, 2,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 2, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       2, 1, 1, 0, 1, 0, 0, 2, 1, 2, 2, 0, 2, 1, 0, 2, 2, 1, 2, 0, 1, 0,\n",
       "       2, 0, 1, 0, 2, 2, 2, 1, 0, 1, 1, 2, 1, 1, 2, 2, 0, 2, 0, 1, 2, 1,\n",
       "       2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 1, 0, 0, 0, 2, 2, 0, 0, 2, 0,\n",
       "       0, 2, 1, 1, 2, 2, 0, 2, 2, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 1, 0, 0,\n",
       "       2, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 2, 2, 1, 2, 0, 2, 2, 0, 1, 2, 0,\n",
       "       1, 0, 2, 0, 2, 0, 0, 0, 0, 2, 1, 0, 1, 2, 0, 2, 0, 0, 0, 1, 2, 2,\n",
       "       2, 0, 1, 0, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 2, 2, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components = 3, max_iter = 100)\n",
    "gmm.fit(XTrain)\n",
    "\n",
    "print(gmm.means_)\n",
    "gmm.predict(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([5.9, 3. , 5.1, 1.8]), array([6.8, 2.8, 4.8, 1.4]), array([7.7, 3.8, 6.7, 2.2])]\n",
      "[array([6.11758764, 2.88281231, 4.84367433, 1.71893362]), array([5.45626353, 3.18753279, 2.52111943, 0.63605117]), array([6.43855402, 3.50749481, 4.00545376, 1.11297982])]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[array([6.11758764, 2.88281231, 4.84367433, 1.71893362]), array([5.45626353, 3.18753279, 2.52111943, 0.63605117]), array([6.43855402, 3.50749481, 4.00545376, 1.11297982])]\n",
      "[1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1\n",
      " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      " 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 2 1 0 0\n",
      " 0 0 0 0 0 0 2 1 1 0 0 1 0 0 2 0 0 0 2 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Use iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Initialize the parameters randomly instead of kmeans\n",
    "k = 3\n",
    "means = []\n",
    "covMats = []\n",
    "for i in range(k):\n",
    "    means.append(X[rd.randint(0, len(X)-1)])\n",
    "    covMats.append(np.cov(X.T))\n",
    "\n",
    "print(means)\n",
    "\n",
    "# Initialize the priors uniformly\n",
    "prior = 1 / len(means)\n",
    "priors = [prior for i in range(len(means))]\n",
    "\n",
    "for i in range(100):\n",
    "    means, covMats, priors = getNewParams(X, means, covMats, priors)\n",
    "\n",
    "print(means)\n",
    "\n",
    "print(y)\n",
    "print(getPredictions(X, means, covMats, priors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems it is not a good idea to just directly compare using label no.\n",
    "This is because the algorithm is only clustering, so if anything we should do a visualization comparison\n",
    "In the above case for example, the first 20 or so points are the same and EM gets that as well. It's just that it labeled it as 1 instead of the original 0. Why? It just got to that cluster later that's it\n",
    "\n",
    "So what did I learn?\n",
    "Don't compare the label values in clustering algorithms directly with a labeled dataset\n",
    "There's a reason it's called clustering instead of classification\n",
    "\n",
    "Yep this was definitely worth the trouble. A lot of new useful knowledge and understanding has been gained here\n",
    "\n",
    "(Also learned that None == [some list] gives [False for l in range(len(list))])\n",
    "\n",
    "This was frustrating and useful at the same time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
